---
layout: post
title: "5 DQN Methods"
subtitle: ''
author: "Tianming Qiu"
header-style: text
mathjax: true
tags:
  - RL
  - DQN
---

## PER
- [Note](http://www.meltycriss.com/2018/03/18/paper-prioritized-experience-replay/)
- [SumTree](https://www.cnblogs.com/pinard/p/9797695.html)
- [PrefixSum Implementation](https://github.com/TianmingQiu/DeepRL-Tutorials)
- [Sample along probability-prefix Sum](https://www.geeksforgeeks.org/random-number-generator-in-arbitrary-probability-distribution-fashion/)
- [Explain on Sumtree k segments](https://jaromiru.com/2016/11/07/lets-make-a-dqn-double-learning-and-prioritized-experience-replay/)
- [MorvanZhou](https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/4-6-prioritized-replay/)
- [A same question as yours](https://stats.stackexchange.com/questions/362036/prioritized-experience-replay-per)



